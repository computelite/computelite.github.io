{
    "Sample_DB": "BEGIN TRANSACTION;\nCREATE TABLE T_QueryLogs (\n\tLogTime      VARCHAR DEFAULT (datetime('now', 'localtime') ),\n\tQuerySQL     VARCHAR,\n\tQueryMsg     VARCHAR\n);\nCREATE TABLE T_TaskLogs (\n        ID              INTEGER PRIMARY KEY AUTOINCREMENT,\n        TaskId          VARCHAR UNIQUE,\n        TaskName        VARCHAR NOT NULL,\n        ProcessId       VARCHAR,\n        TaskStatus      VARCHAR,\n        StartDate       VARCHAR DEFAULT (datetime('now', 'localtime') ),\n        EndDate         VARCHAR,\n        ErrorMsg        VARCHAR,\n        Alerted         INTEGER DEFAULT (0),\n        TaskDbId        VARCHAR,\n        MasterTaskId    VARCHAR\n);\n\nCREATE TABLE T_SolverLog (\n    LogTime    VARCHAR DEFAULT (datetime('now', 'localtime') ),\n    LogMessage VARCHAR\n);\n\nCREATE TABLE S_ModelParams (\n    ParamName    VARCHAR,\n    ParamValue   VARCHAR\n);\nINSERT INTO S_ModelParams VALUES('ModelIcon','fas fa-cube');\nINSERT INTO S_ModelParams VALUES('ModelName','Sample DB');\nINSERT INTO S_ModelParams VALUES('DBVersion','1.0.0');\n\nCREATE TABLE S_TableParameters (\n    TableName      VARCHAR,\n    ColumnName     VARCHAR,\n    ParameterType  VARCHAR,\n    ParameterValue VARCHAR,\n    UNIQUE(TableName,ColumnName,ParameterType)\n);\n\nCREATE TABLE S_TableGroup (\n    GroupName        VARCHAR,\n    TableName        VARCHAR,\n    TableDisplayName VARCHAR,\n    TableType        VARCHAR,\n    ColumnOrder      VARCHAR,\n    Table_Status     VARCHAR,\n    Freeze_Col_Num   NUMERIC\n);\nINSERT INTO S_TableGroup VALUES('Log Tables','T_TaskLogs','Task Logs','Task Logs',NULL,'Active',NULL);\nINSERT INTO S_TableGroup VALUES('Log Tables','T_SolverLog','Solver Logs','Solver Logs',NULL,'Active',NULL);\nINSERT INTO S_TableGroup VALUES('Setups','S_TableGroup','Table Group','Input',NULL,'Active',NULL);\nINSERT INTO S_TableGroup VALUES('Setups','S_TableParameters','Table Parameters','Input',NULL,'Active',NULL);\nINSERT INTO S_TableGroup VALUES('Setups','S_TaskMaster','Task Master','Input',NULL,'Active',NULL);\nINSERT INTO S_TableGroup VALUES('Setups','S_ExecutionFiles','Code Files','Input',NULL,'Active',NULL);\nINSERT INTO S_TableGroup VALUES('All Other','V_TEMPV','Temp View','Output',NULL,'Active',NULL);\nINSERT INTO S_TableGroup VALUES('All Other','S_DataFiles','Data Files','Input','[\"FileId\",\"FileName\",\"FileType\",\"Status\"]','Active',NULL);\nINSERT INTO S_TableGroup VALUES('All Other','S_PackageWheels','PackageWheels','Input','[\"WheelId\",\"WheelName\",\"Status\"]','Active',NULL);\nINSERT INTO S_TableGroup VALUES('All Other','S_PyNotebook','Python Notebook','Input',NULL,'Active',NULL);\nINSERT INTO S_TableGroup VALUES('All Other','S_JsNotebook','Javascript Notebook','Input',NULL,'Active',NULL);\nINSERT INTO S_TableGroup VALUES('All Other','S_RNotebook','R Notebook','Input',NULL,'Active',NULL);\nINSERT INTO S_TableGroup VALUES('All Other','S_Notebooks','Notebooks','Input',NULL,'Active',NULL);\nINSERT INTO S_TableGroup VALUES('All Other','S_NotebookContent','Notebook Contents','Input',NULL,'Active',NULL);\nCREATE TABLE S_TaskMaster (\n\tTaskId\t            INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n\tTaskName\t        VARCHAR,\n\tTaskDisplayName\t    VARCHAR,\n\tTaskParameters\t    VARCHAR,\n\tTaskStatus\t        VARCHAR,\n\tTaskLastRunDate\t    VARCHAR,\n\tTaskOutput\t        VARCHAR\n);\nINSERT INTO S_TaskMaster VALUES(1,'cats.py','Download Cats',NULL,NULL,NULL,NULL);\nINSERT INTO S_TaskMaster VALUES(2,'dogs.py','Show Dog',NULL,NULL,NULL,NULL);\nCREATE TABLE S_ExecutionFiles (\n\tFileId\t            INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n\tFileName\t        VARCHAR,\n\tFileLabel   \t    VARCHAR,\n    FilePath            VARCHAR UNIQUE,\n    FileData            VARCHAR,\n\tStatus\t            VARCHAR DEFAULT ('Active')\t\n);\nINSERT INTO S_ExecutionFiles VALUES(1,'main.py',NULL,'main.py',replace('from foo.bar import main as bar\nfrom foo.foo import main as foo\n\nprint(\"Hello from main.py\")\nbar()\nfoo()','\n',char(10)),'Active');\nINSERT INTO S_ExecutionFiles VALUES(2,'bar.py',NULL,'foo/bar.py',replace('def main():\n    print(\"Hello from bar.py\")','\n',char(10)),'Active');\nINSERT INTO S_ExecutionFiles VALUES(3,'foo.py',NULL,'foo/foo.py',replace('def main():\n    print(\"Hello from foo.py\")','\n',char(10)),'Active');\nINSERT INTO S_ExecutionFiles VALUES(4,'requirements.txt',NULL,'requirements.txt',replace('urllib3\nPillow\npandas\nsqlite3\npulp\nhighspy','\n',char(10)),'Active');\nINSERT INTO S_ExecutionFiles VALUES(5,'dogs.py',NULL,'dogs.py',replace('# Sample code to display random dog images \nimport urllib3, json, os,io\nfrom pyodide.ffi import to_js\n\nurl = \"https://random.dog/woof.json\"\nresponse  = urllib3.request(\"GET\", url)\nimg_url = response.json()[''url'']\n\nextension = \"\"\n\nwhile extension not in (\"JPEG\", \"PNG\", \"JPG\", \"GIF\"):\n    response  = urllib3.request(\"GET\", url)\n    img_url = response.json()[''url'']\n    print(img_url)\n    extension = img_url.split(\".\")[-1].upper()\n\nresponse = urllib3.request(\"GET\", img_url)\n\nbuf = io.BytesIO(response.data)\n\nto_js(buf.getvalue())','\n',char(10)),'Active');\nINSERT INTO S_ExecutionFiles VALUES(6,'cats.py',NULL,'cats.py',replace('# Sample code to download random cat images \nimport urllib3, os,io, shutil\nfrom pyodide.ffi import to_js\nfrom PIL import Image\n\n# This is the Output Dir, which is accessible from HomePage\noutput_dir = r''outputDir/''\n\nexpected_size_collage = (900, 900)\nexpected_size_image = (300, 300)\n\ncollage = Image.new(\"RGBA\", expected_size_collage, color=(255,255,255,255))\nurl = \"https://cataas.com/cat?type=square\"\n\nfor h in range(0, expected_size_collage[1], expected_size_image[1]):\n    for w in range(0, expected_size_collage[0], expected_size_image[0]):\n        image_data  = urllib3.request(\"GET\", url).data\n        image = Image.open(io.BytesIO(image_data)).convert(\"RGBA\")\n\n        # Get the original image width and height\n        image_width = image.size[0]\n        image_height = image.size[1]\n\n        # Get how the width and height should be\n        width_factor = image_width / expected_size_image[0]\n        height_factor = image_height / expected_size_image[1]\n\n        image = image.resize(expected_size_image)\n\n        # Copy image to collage canvas\n        collage.paste(image, (w, h))\n\nout_collage = io.BytesIO()\ncollage.save(out_collage, \"PNG\")\n\n# Saving to outputDir, so it could be visible from HomePage \"Files --> OutputFiles\"\ncollage.save(''outputDir/cats.png'')\nout_collage.seek(0)\nto_js(out_collage.getvalue())','\n',char(10)),'Active');\nINSERT INTO S_ExecutionFiles VALUES(7,'list_input_files.py',NULL,'list_input_files.py',replace('import os\nprint(os.listdir(\"inputDir\"))','\n',char(10)),'Active');\nINSERT INTO S_ExecutionFiles VALUES(8,'pandaas.py',NULL,'pandaas.py',replace('import sqlite3\nimport pandas as pd\n\n# thisDB is a keyword for current SQLite database\nconn = sqlite3.connect(thisDB)\n\ndf = pd.read_sql_query(\"SELECT * from sqlite_master\", conn)\n\nall_tables = list(df[''tbl_name''][df.type == ''table''])\n\nfor table_name in all_tables:\n    query = f\"select count(*) from [{table_name}]\" \n    res = conn.execute(query).fetchall()\n    count = res[0][0]\n    if count > 0:\n        output_str = f\"Table {table_name} has {count} records\"\n        print(output_str)\n','\n',char(10)),'Active');\nINSERT INTO S_ExecutionFiles VALUES(9,'write_output_file.py',NULL,'write_output_file.py',replace('import os\n\n# This is the Output Dir, which is accessible from HomePage\noutput_dir = r''outputDir''\n\ninput_file_name = f''{output_dir}/output_file.txt''\nwith open(input_file_name, ''w'') as fl:\n    for i in range(100):\n  \t    fl.write(f''Hello from ComputeLite! count({i+1})'')\n    fl.close()\n  \nz = os.listdir(output_dir)\nprint(z)','\n',char(10)),'Active');\nINSERT INTO S_ExecutionFiles VALUES(10,'update_sqlite_db.py',NULL,'update_sqlite_db.py',replace('import sqlite3\n\nquery = \"INSERT INTO T_SolverLog (LogMessage) Values (''Hello from ComputeLite'')\"\n\nwith sqlite3.connect(thisDB) as conn:\n    conn.execute(query)\n  \n# Check solver log table: Log Tables > Solver Logs\n','\n',char(10)),'Active');\nINSERT INTO S_ExecutionFiles VALUES(11,'blending_problem_with_pulp_highs.py',NULL,'blending_problem_with_pulp_highs.py',replace('# Import PuLP modeler functions\nfrom pulp import *\n\n# Create the ''prob'' variable to contain the problem data\nprob = LpProblem(\"The Whiskas Problem\", LpMinimize)\n# The 2 variables Beef and Chicken are created with a lower limit of zero\nx1 = LpVariable(\"ChickenPercent\", 0, None, LpInteger)\nx2 = LpVariable(\"BeefPercent\", 0)\n\n# The objective function is added to ''prob'' first\nprob += 0.013 * x1 + 0.008 * x2, \"Total Cost of Ingredients per can\"\n\n# The five constraints are entered\nprob += x1 + x2 == 100, \"PercentagesSum\"\nprob += 0.100 * x1 + 0.200 * x2 >= 8.0, \"ProteinRequirement\"\nprob += 0.080 * x1 + 0.100 * x2 >= 6.0, \"FatRequirement\"\nprob += 0.001 * x1 + 0.005 * x2 <= 2.0, \"FibreRequirement\"\nprob += 0.002 * x1 + 0.005 * x2 <= 0.4, \"SaltRequirement\"\n\nsolver = HiGHS() #Define HiGHS solver, include highspy in requirement.txt\nprob.writeLP(\"outputDir/WhiskasModel.lp\")\nprob.solve(solver) #Use HiGHS solver\nprint(\"Status:\", LpStatus[prob.status])\n\nfor v in prob.variables():\n    print(v.name, \"=\", v.varValue)\n\nprint(\"Total Cost of Ingredients per can = \", value(prob.objective))','\n',char(10)),'Active');\nCREATE TABLE S_DataFiles (\n\tFileId\t            INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n\tFileName\t        VARCHAR,\n\tFileType   \t        VARCHAR,\n    FileBlob            BLOB NOT NULL,\n\tStatus\t            VARCHAR DEFAULT ('Active'),\n    UNIQUE(FileName,FileType)\t\n);\n\nCREATE TABLE S_PackageWheels (\n\tWheelId\t            INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n\tWheelName\t        VARCHAR UNIQUE,\n    WheelBlob            BLOB NOT NULL,\n\tStatus\t            VARCHAR DEFAULT ('Active')\t\n);\n\nCREATE TABLE S_Notebooks (\n\tNotebookId\t    INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n\tName            VARCHAR,\n\tType\t\t\tVARCHAR,\n\tStatus\t    \tVARCHAR DEFAULT 'Active',\n\tCreationDate\tVARCHAR DEFAULT (datetime('now','localtime')),\n\tLastUpdateDate\tVARCHAR DEFAULT (datetime('now','localtime'))\n);\n\nINSERT INTO S_Notebooks VALUES(1,'Default','Javascript','Active','2025-03-17 10:52:35','2025-03-17 10:52:35');\nINSERT INTO S_Notebooks VALUES(2,'Default','Python','Active','2025-03-17 10:52:35','2025-03-17 10:52:35');\nINSERT INTO S_Notebooks VALUES(3,'Test2','Javascript','Active','2025-03-17 10:53:42','2025-03-17 10:53:42');\n\nCREATE TABLE S_NotebookContent (\n    CellId\t        INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n\tName            VARCHAR,\n    NotebookId      INTEGER NOT NULL,    \n\tCellContent\t    VARCHAR,\n    CellType        VARCHAR,\n\tCreationDate\tVARCHAR DEFAULT (datetime('now','localtime')),\n\tLastUpdateDate\tVARCHAR DEFAULT (datetime('now','localtime'))\n);\nINSERT INTO S_NotebookContent VALUES(1,'Default',1,replace('// Load external libraries dynamically from a CDN using loadCDNScripts\nawait loadCDNScripts([{ url: \"https://cdn.jsdelivr.net/npm/lodash/lodash.min.js\", globalVar: \"_\" },\n    { url: \"https://cdn.jsdelivr.net/npm/dayjs/dayjs.min.js\", globalVar: \"dayjs\" },\n    { url: \"https://cdn.jsdelivr.net/npm/chart.js\", globalVar: \"Chart\" }\n]);\n\nconsole.log(_.chunk([1, 2, 3, 4], 2));\n\nconsole.log(dayjs().format());\n\nconst canvas = document.createElement(\"canvas\");\nconst ctx = canvas.getContext(\"2d\");\nnew Chart(ctx, {\n    type: \"bar\",\n    data: {\n        labels: [\"Red\", \"Blue\", \"Yellow\"],\n        datasets: [{ \n            label: \"Votes\",\n            data: [12, 19, 3],\n            backgroundColor: [\"red\", \"blue\", \"yellow\"] \n        }] \n    } \n});\ncanvas','\n',char(10)),'javascript','2025-03-17 10:52:35','2025-03-17 10:52:35');\nINSERT INTO S_NotebookContent VALUES(2,'Default',1,replace('// Fetch data from the database\n// The executeQuery function executes an SQL query and retrieves data from the database.\n// In this case, we are selecting all records from the ''S_tablegroup'' table.\n\nconst result = await executeQuery(\"select * from S_tablegroup\")\nconsole.log(\"result\", result);','\n',char(10)),'javascript','2025-03-17 10:52:35','2025-03-17 10:52:35');\nINSERT INTO S_NotebookContent VALUES(3,'Default',1,replace('// Load external CSS dynamically from a CDN using loadCDNStylesheets\n\nawait loadCDNStylesheets([\n    { url: \"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\" }\n]);','\n',char(10)),'javascript','2025-03-17 10:52:35','2025-03-17 10:52:35');\nINSERT INTO S_NotebookContent VALUES(4,'Default',2,'print(\"Hello ComputeLite\")','python','2025-03-17 10:52:47','2025-03-17 10:52:47');\nINSERT INTO S_NotebookContent VALUES(5,'Test2',3,'console.log(\"Hello\")','javascript','2025-03-17 10:53:42','2025-03-17 10:53:42');\n\n\nCREATE VIEW V_TEMPV\nAS SELECT 1;\nCOMMIT;"
}